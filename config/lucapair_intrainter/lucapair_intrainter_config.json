{
  "directionality": "encoder",
  "vocab_size": 44,
  "token_type_size": 4,
  "max_position_embeddings": 2048,
  "use_rotary_position_embeddings": true,
  "rope_theta": 10000,
  "use_token_type_embeddings": true,
  "self_encoder_layers": 4,
  "self_attention_heads": 8,
  "self_kv_attention_heads": 8,
  "cross_encoder_layers": 4,
  "cross_attention_heads": 8,
  "cross_kv_attention_heads": 8,
  "encoder_ffn_dim": 4096,
  "encoder_layer_dropout": 0.0,
  "layer_norm_type": "post",
  "layer_norm_name": "RMSNorm",
  "layer_norm_eps": 1e-6,
  "activation_function": "gelu",
  "embedding_input_size_a": 2560,
  "embedding_input_size_b": 2560,
  "hidden_size": 1024,
  "attn_type": "eager",
  "dropout": 0.0,
  "attention_dropout": 0.0,
  "activation_dropout": 0.0,
  "classifier_dropout": 0.1,
  "scale_embedding": false,
  "init_std": 0.02,
  "num_labels": 2,
  "pad_token_id": 0,
  "unk_token_id": 1,
  "bos_token_id": 2,
  "eos_token_id": 3,
  "mask_token_id": 4,
  "use_swiglu_ffn": false,
  "multiple_of":  256,
  "ffn_dim_multiplier": null,
  "use_moe": false,
  "moe_activation_function": "gelu",
  "moe_num_experts": 8,
  "moe_hidden_dim": 6912,
  "moe_top_k": 2
}